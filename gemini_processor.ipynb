{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def localtime_to_str():\n",
    "    return time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime())\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=f\"data/output/gemini/log/gemini_{localtime_to_str()}.log\", \n",
    "    encoding=\"utf-8\",\n",
    "    level=logging.DEBUG\n",
    "    )\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "def create_dir(base_dir=\"data/output/gemini/responses\") -> str:\n",
    "    \"\"\"\n",
    "    指定したベースディレクトリに、日付と連番を組み合わせた名称のディレクトリを作成する。\n",
    "    既に同名のディレクトリが存在する場合、連番をインクリメントして新たなディレクトリを作成する。\n",
    "\n",
    "    Args:\n",
    "        base_dir: ベースとなるディレクトリのパス (デフォルト: \"data/output/gemini/responses\")\n",
    "\n",
    "    Returns:\n",
    "        str: 作成されたディレクトリの相対パス\n",
    "    \"\"\"\n",
    "\n",
    "    today = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "    num = 1\n",
    "\n",
    "    while True:\n",
    "        dir_name = f\"{base_dir}/{today}_{num:03d}\"  # 連番を3桁で表示\n",
    "        try:\n",
    "            if not os.path.exists(dir_name):\n",
    "                os.makedirs(dir_name)\n",
    "                return dir_name\n",
    "            num += 1\n",
    "        except OSError as e:\n",
    "            print(f\"ディレクトリ作成中にエラーが発生しました: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-exp\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_condition_of_the_incident = \"\"\"\n",
    "### 指示 ###\n",
    "あなたは製品の事故原因を分析しています。\n",
    "事故の通知内容から、被害の様子を単純に説明してください。\n",
    "回答形式はJSON形式です。\n",
    "\n",
    "### 回答形式 ###\n",
    "{\n",
    "\t\"被害\":\"回答\"\n",
    "}\n",
    "\n",
    "### 注意事項 ###\n",
    "- 指示された回答のみ出力してください。\n",
    "- 被害の様子を最もよく説明する単語のみで回答してください。\n",
    "- 被害は複数回答してもかまいません。その場合、配列で記述してください。\n",
    "- 解説は不要です。\n",
    "\n",
    "### 例 ###\n",
    "事故の通知内容:\n",
    "カセットこんろの五徳付プレートを洗っていたところ、指が切れ、第一関節裏側を2針縫った。\n",
    "\n",
    "回答:\n",
    "{\n",
    "\t\"被害\":\"裂傷\"\n",
    "}\n",
    "\n",
    "### 例の解説 ###\n",
    "「指が切れ」という記述から、「裂傷」を負ったと判断できます。\n",
    "\n",
    "### 事故の通知内容 ###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cause_of_the_incident = \"\"\"\n",
    "### 指示 ###\n",
    "あなたは製品の事故原因を分析しています。\n",
    "事故の内容から、事故の原因を単純に説明してください。\n",
    "回答形式はJSON形式です。\n",
    "\n",
    "### 回答形式 ###\n",
    "{\n",
    "\t\"原因\":\"回答\"\n",
    "}\n",
    "\n",
    "### 注意事項 ###\n",
    "- 指示された回答のみ出力してください。\n",
    "- 事故の原因を最もよく説明する単語のみで回答してください。\n",
    "- 原因は複数回答してもかまいません。その場合、配列で記述してください。\n",
    "- 解説は不要です。\n",
    "\n",
    "### 例 ###\n",
    "事故の内容:\n",
    "五徳付プレートの外側の縁が処理されておらず、多少ざらついていることから、素手でプレートを洗っていた際に、外側の縁に指を強く擦りつけたため、負傷したものと推定される。なお、取扱説明書には「手、指の保護のため、必ずゴム手袋などを使用してください。」との注意が記載されている。\n",
    "\n",
    "回答:\n",
    "{\n",
    "\t\"原因\":[\"縁\",\"接触\"]\n",
    "}\n",
    "\n",
    "### 例の解説 ###\n",
    "「縁に指を強く擦りつけた」という記述から、「縁」、「接触」が原因であると判断できます。\n",
    "\n",
    "### 事故の内容 ###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "global former_data\n",
    "former_data = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json_response(\n",
    "        prompt:str, \n",
    "        data:pd.DataFrame, \n",
    "        response_name:str, \n",
    "        chat_session:genai.ChatSession,\n",
    "        request_interval:int=6\n",
    "        ) -> None:\n",
    "    global former_data\n",
    "    for i in tqdm(range(0, len(data))):\n",
    "        if data.values[i] == former_data:\n",
    "            logger.debug(f\"Skipped: {data.values[i]}\")\n",
    "            data.values[i] = data.values[i-1]\n",
    "            continue\n",
    "        input_prompt = prompt + data.values[i]\n",
    "        former_data = data.values[i]\n",
    "        try:\n",
    "            response = chat_session.send_message(input_prompt)\n",
    "            temp = response.text\n",
    "            if \"```json\" in temp:\n",
    "                temp = temp.replace(\"```json\", \"\")\n",
    "                temp = temp.replace(\"```\", \"\")\n",
    "            res = json.loads(temp)\n",
    "            logger.debug(temp)\n",
    "        except Exception as e:\n",
    "            logger.error(\"Error\", e, temp)\n",
    "            continue\n",
    "        output_text = \"\"\n",
    "        if isinstance(res[response_name], list):\n",
    "            for text in res[response_name]:\n",
    "                output_text += text + \" \"\n",
    "        else:\n",
    "            output_text = res[response_name]\n",
    "        logger.debug(f\"Output: {output_text}\")\n",
    "        data.values[i] = output_text\n",
    "        time.sleep(request_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings as st\n",
    "\n",
    "output_dir = create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor(product:str)->None:\n",
    "    data = pd.read_csv(f\"data/output/gemini/prompt_data/{product}.csv\", encoding=\"utf-8-sig\")\n",
    "    generate_json_response(\n",
    "        prompt=prompt_condition_of_the_incident, \n",
    "        data=data[\"事故通知内容\"], \n",
    "        response_name=\"被害\", \n",
    "        chat_session=chat_session\n",
    "        )\n",
    "    generate_json_response(\n",
    "        prompt=prompt_cause_of_the_incident, \n",
    "        data=data[\"事故原因\"], \n",
    "        response_name=\"原因\", \n",
    "        chat_session=chat_session\n",
    "        )\n",
    "    print(data.head())\n",
    "    data.to_csv(f\"{output_dir}/{product}_res.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1fcdc1f4f941059dfe5e12d85db9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chika\\AppData\\Local\\Temp\\ipykernel_11796\\325136422.py\", line 17, in generate_json_response\n",
      "    response = chat_session.send_message(input_prompt)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\generativeai\\generative_models.py\", line 578, in send_message\n",
      "    response = self.model.generate_content(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\generativeai\\generative_models.py\", line 331, in generate_content\n",
      "    response = self._client.generate_content(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py\", line 830, in generate_content\n",
      "    response = rpc(\n",
      "               ^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py\", line 131, in __call__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 293, in retry_wrapped_func\n",
      "    return retry_target(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 153, in retry_target\n",
      "    _retry_error_helper(\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py\", line 212, in _retry_error_helper\n",
      "    raise final_exc from source_exc\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 144, in retry_target\n",
      "    result = target()\n",
      "             ^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py\", line 120, in func_with_timeout\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py\", line 78, in error_remapped_callable\n",
      "    raise exceptions.from_grpc_error(exc) from exc\n",
      "google.api_core.exceptions.DeadlineExceeded: 504 Deadline Exceeded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\chika\\anaconda3\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\anaconda3\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\anaconda3\\Lib\\logging\\__init__.py\", line 703, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chika\\anaconda3\\Lib\\logging\\__init__.py\", line 392, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\chika\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\chika\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\chika\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\chika\\Documents\\VSCode\\research-utils\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\chika\\AppData\\Local\\Temp\\ipykernel_11796\\4176092785.py\", line 1, in <module>\n",
      "    processor(st.products_250115[3])\n",
      "  File \"C:\\Users\\chika\\AppData\\Local\\Temp\\ipykernel_11796\\1020681445.py\", line 3, in processor\n",
      "    generate_json_response(\n",
      "  File \"C:\\Users\\chika\\AppData\\Local\\Temp\\ipykernel_11796\\325136422.py\", line 25, in generate_json_response\n",
      "    logger.error(\"Error\", e, temp)\n",
      "Message: 'Error'\n",
      "Arguments: (DeadlineExceeded('Deadline Exceeded'), '{\\n\\t\"被害\":\"発煙\"\\n}\\n')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee5553586a04949968215887d10a9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    No    事故通知内容                  事故原因\n",
      "0  272        火傷              火薬漏れ 噴火 \n",
      "1  273    痛み 腫れ               レーザー光照射 \n",
      "2  479  漏れ出し 炎症       注意表示不十分 保護者注意不足 \n",
      "3  494        火傷     着火薬吸湿 火薬部直接着火 火傷 \n",
      "4  580     眼底出血   安全キャップ不装着 安全装置解除 誤射 \n"
     ]
    }
   ],
   "source": [
    "processor(st.products_250115[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
